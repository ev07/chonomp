{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_opener import open_dataset_and_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee30a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"natural_stats.csv\")\n",
    "#NaN convert int to floats, make sure that variable names are strings.\n",
    "df_results['target'] = df_results['target'].apply(lambda x: x if pd.isnull(x) or isinstance(x,str) else str(int(x)))\n",
    "df_results['association_chosen'] = df_results['association_chosen'].apply(lambda x: x if pd.isnull(x) or isinstance(x,str) else str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.replace(to_replace=\"SynthNonlin/7ts2h\", value=\"7ts2h\")\n",
    "df_results = df_results.replace(to_replace=\"fMRI_processed_by_Nauta/returns/our_selection\", value=\"fMRI\")\n",
    "df_results = df_results.replace(to_replace=\"TestCLIM_N-5_T-250/returns\", value=\"CLIM\")\n",
    "df_results = df_results.replace(to_replace=\"FinanceCPT/returns/our_selection\", value=\"Finance\")\n",
    "df_results = df_results.replace(to_replace=\"VARProcess/returns\", value = \"VARProcess\")\n",
    "df_results = df_results.replace(to_replace=\"VARProcessNoCorr/returns\", value = \"VARProcessNoCorr\")\n",
    "df_results = df_results.replace(to_replace=\"VARLarge/returns\", value = \"VARLarge\")\n",
    "df_results = df_results.replace(to_replace=\"VARSmall/returns\", value = \"VARSmall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12576a41",
   "metadata": {},
   "source": [
    "Type 1 error: failing to accept a null hypothesis\n",
    "Type 2 error: failing to reject a null hypothesis\n",
    "\n",
    "    \n",
    "What would be TP, TN, FP, FN?\n",
    "- Look at association with residuals, not just highest association.\n",
    "- Change correlation to p-values\n",
    "- Add within the algorithm 4 columns at each step: TP, TN, FP, FN counts on associations because it is too cumbersome to do it afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a815ce7",
   "metadata": {},
   "source": [
    "So, what do I need to show?\n",
    "- Step by step, how many inclusion error have been made by the highest association ?\n",
    "  - More precisely: selecting a variable that isn't causal  => AKA False Positive w.r.t. the selection\n",
    "  - Same question when restricting to data where the algorithm has made no wrong decision beforehand\n",
    "  - Same question when restricting to data where the algorithm hasn't normally terminated\n",
    "  - Same question when adjusting for the number of causal variables remaining to be selected\n",
    "- Step by step, how many TP,FP,FN,TN with the association ?\n",
    "  - Same question when restricting to data where the algorithm has made no wrong decision beforehand\n",
    "  - Same question when restricting to data where the algorithm hasn't normally terminated\n",
    "- Step by step, how many true positive and false positive have been made by the stopping criterion?\n",
    "  - Same question when restricting to data where the algorithm has made no wrong decision beforehand\n",
    "  - Same question when restricting to data where the algorithm has normally terminated\n",
    "- Performance of final model vs Performance of causal model\n",
    "  - Same question but for each number of selected variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32123284",
   "metadata": {},
   "source": [
    "### ARDL - VARProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdab2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to show that the training is long enough.\n",
    "# show the distribution of the difference between two timesteps\n",
    "df = df_results[df_results[\"dataset\"]==\"VARSmall\"]\n",
    "df = df[df[\"model\"]==\"ARDL\"]\n",
    "df = df[df[\"association\"]==\"Pearson\"]\n",
    "df = df[df[\"stopping_criterion\"]==\"f-test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e968e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db55a3",
   "metadata": {},
   "source": [
    "## Trained model statistics along algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I want to show the evolution of several indicators of the models at different iterations\n",
    "newdf = []\n",
    "\n",
    "metrics_name_list = [\"train_sse\",\"train_llh\",\"train_aic\", \"train_rmse\", \"train_R2\"]\n",
    "\n",
    "for metric_name in metrics_name_list:\n",
    "    for group_name,group in df.groupby([\"filename\",\"target\"]):\n",
    "        differenciated_metric = np.diff(group[[\"step\",metric_name]].sort_values(\"step\")[metric_name])\n",
    "        for i, element in enumerate(differenciated_metric):\n",
    "            new_row = {\"new - old\":element, \"metric\":metric_name,\"Vars in new model\":i+2}\n",
    "            newdf.append(new_row)\n",
    "    \n",
    "newdf = pd.DataFrame(newdf)\n",
    "\n",
    "g = sns.FacetGrid(data=newdf,col=\"metric\", sharey=False)\n",
    "g.map_dataframe(sns.lineplot,x=\"Vars in new model\",y=\"new - old\",errorbar=('ci', 99))\n",
    "\n",
    "for i,ax in enumerate(g.axes[0]):\n",
    "    ax.plot([2,10],[0,0],c=\"black\")\n",
    "    if metrics_name_list[i] in [\"train_llh\",\"test_llh\",\"train_R2\",\"test_R2\"]:\n",
    "        maxval = ax.get_ylim()[1]\n",
    "        r = matplotlib.patches.Rectangle((2,0),8,maxval,alpha=0.2,facecolor=\"green\")\n",
    "        ax.add_patch(r)\n",
    "    else:\n",
    "        minval = ax.get_ylim()[0]\n",
    "        r = matplotlib.patches.Rectangle((2,minval),8,-minval,alpha=0.2,facecolor=\"green\")\n",
    "        ax.add_patch(r)\n",
    "\n",
    "g.fig.subplots_adjust(top=0.72)\n",
    "_=g.fig.suptitle(\"Difference between consecutive algorithm steps.\\nThe new model is better than the previous model if the difference is in the green zone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I want to show the evolution of several indicators of the models at different iterations\n",
    "newdf = []\n",
    "\n",
    "metrics_name_list = [\"test_sse\", \"test_rmse\", \"test_R2\"]\n",
    "\n",
    "for metric_name in metrics_name_list:\n",
    "    for group_name,group in df.groupby([\"filename\",\"target\"]):\n",
    "        differenciated_metric = np.diff(group[[\"step\",metric_name]].sort_values(\"step\")[metric_name])\n",
    "        for i, element in enumerate(differenciated_metric):\n",
    "            new_row = {\"new - old\":element, \"metric\":metric_name,\"Vars in new model\":i+2}\n",
    "            newdf.append(new_row)\n",
    "    \n",
    "newdf = pd.DataFrame(newdf)\n",
    "\n",
    "g = sns.FacetGrid(data=newdf,col=\"metric\", sharey=False)\n",
    "g.map_dataframe(sns.lineplot,x=\"Vars in new model\",y=\"new - old\",errorbar=('ci', 99))\n",
    "\n",
    "for i,ax in enumerate(g.axes[0]):\n",
    "    ax.plot([2,10],[0,0],c=\"black\")\n",
    "    if metrics_name_list[i] in [\"train_llh\",\"test_llh\",\"train_R2\",\"test_R2\"]:\n",
    "        maxval = ax.get_ylim()[1]\n",
    "        r = matplotlib.patches.Rectangle((2,0),8,maxval,alpha=0.2,facecolor=\"green\")\n",
    "        ax.add_patch(r)\n",
    "    else:\n",
    "        minval = ax.get_ylim()[0]\n",
    "        r = matplotlib.patches.Rectangle((2,minval),8,-minval,alpha=0.2,facecolor=\"green\")\n",
    "        ax.add_patch(r)\n",
    "\n",
    "g.fig.subplots_adjust(top=0.72)\n",
    "_=g.fig.suptitle(\"Difference between consecutive algorithm steps.\\nThe new model is better than the previous model if the difference is in the green zone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71acc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc63ad",
   "metadata": {},
   "source": [
    "## Time spent at different levels of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa085b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(df[\"totaltime\"])\n",
    "_=g.axes[0][0].set_title(\"Distribution of the execution time (s) of the algorithm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(131)\n",
    "g = sns.lineplot(df,x=\"step\",y=\"previous_model_time\",ax=ax)\n",
    "ax = plt.subplot(133)\n",
    "g = sns.lineplot(df,x=\"step\",y=\"associations_time\",ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5966ca8",
   "metadata": {},
   "source": [
    "## Final itemset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall TP,FP,TN,FN sur le r√©sultat final de l'algo\n",
    "\n",
    "#select only timestep of natural termination\n",
    "df1 = df[~df[\"current_is_last_model\"].isnull()]\n",
    "df1 = df1[df1[\"current_is_last_model\"]]\n",
    "#aggregate TP, TN, FP, FN\n",
    "df1[[\"final_TP\",\"final_FP\",\"final_TN\",\"final_FN\"]].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791197a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "TP,FP,TN,FN=df1[[\"final_TP\",\"final_FP\",\"final_TN\",\"final_FN\"]].sum(axis=0)\n",
    "y_true,y_pred = [1]*TP,[1]*TP\n",
    "y_true,y_pred = y_true+[0]*FP,y_pred+[1]*FP\n",
    "y_true,y_pred = y_true+[0]*TN,y_pred+[0]*TN\n",
    "y_true,y_pred = y_true+[1]*FN,y_pred+[0]*FN\n",
    "cm=confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"Non-causal\",\"Causal\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final rmse of selected model vs rmse of causal model\n",
    "\n",
    "#select only timestep of natural termination\n",
    "df1 = df[~df[\"current_is_last_model\"].isnull()]\n",
    "df1 = df1[df1[\"current_is_last_model\"]]\n",
    "\n",
    "g = sns.scatterplot(df1,x=\"test_rmse\",y=\"causal_test_rmse\")\n",
    "xlim,ylim = g.axes.get_xlim(),g.axes.get_ylim()\n",
    "mini,maxi = min(xlim[0],ylim[0]),max(xlim[1],ylim[1])\n",
    "g.axes.plot([mini,maxi],[mini,maxi],color=\"black\")\n",
    "g.axes.set_xlim(xlim)\n",
    "g.axes.set_ylim(ylim)\n",
    "g.axes.set_title(\"test RMSE of selected model vs test RMSE of Causal Model\")\n",
    "\n",
    "# wilcoxon test\n",
    "print(\"Using wilcoxon signed rank test:\")\n",
    "print(\"p-value of test H0: rmse of selected model >= rmse causal model: \",scipy.stats.wilcoxon(df1[\"test_rmse\"],df1[\"causal_test_rmse\"],alternative=\"less\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3779321",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final r2 of selected model vs r2 of causal model\n",
    "\n",
    "#select only timestep of natural termination\n",
    "df1 = df[~df[\"current_is_last_model\"].isnull()]\n",
    "df1 = df1[df1[\"current_is_last_model\"]]\n",
    "\n",
    "g = sns.scatterplot(df1,x=\"test_R2\",y=\"causal_test_R2\")\n",
    "xlim,ylim = g.axes.get_xlim(),g.axes.get_ylim()\n",
    "mini,maxi = min(xlim[0],ylim[0]),max(xlim[1],ylim[1])\n",
    "g.axes.plot([mini,maxi],[mini,maxi],color=\"black\")\n",
    "g.axes.set_xlim(xlim)\n",
    "g.axes.set_ylim(ylim)\n",
    "g.axes.set_title(\"test R2 of selected model vs test R2 of Causal Model\")\n",
    "\n",
    "# wilcoxon test\n",
    "print(\"Using wilcoxon signed rank test:\")\n",
    "print(\"p-value of test H0: r2 of selected model >= r2 causal model: \",scipy.stats.wilcoxon(df1[\"test_R2\"],df1[\"causal_test_R2\"],alternative=\"less\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2c922",
   "metadata": {},
   "source": [
    "## Choices along algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88477f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of good and bad inclusions by step of the algo\n",
    "# only include variables that are actually part of the returned set.\n",
    "\n",
    "#select only timesteps before natural termination\n",
    "df1 = df[~df[\"should_have_stopped\"].isnull()]\n",
    "df1 = df1[~df1[\"should_have_stopped\"]]\n",
    "#exclude timestep of termination since the variable is said non significant by stopping criterion\n",
    "df1 = df1[~df1[\"current_is_last_model\"]]\n",
    "\n",
    "# aggregate by causal type\n",
    "df1[[\"step\",\"chosen_in_ground_truth\",\"train_aic\"]].groupby([\"step\",\"chosen_in_ground_truth\"]).count().rename(columns={'train_aic':\"Count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall TP, FP, TN, FN of association as the algo progress\n",
    "\n",
    "#select only timesteps before natural termination\n",
    "df1 = df[~df[\"should_have_stopped\"].isnull()]\n",
    "df1 = df1[~df1[\"should_have_stopped\"]]\n",
    "# here we include associations computed from the last trained model residuals (which doesnt lead to new variable selection).\n",
    "# to only get associations where chosen variable is significant according to the stopping criterion, add line below:\n",
    "# df1 = df1[~df1[\"current_is_last_model\"]]\n",
    "\n",
    "#aggregate TP, TN, FP, FN\n",
    "print(\"TP: causal variable is detected as correlated with the residuals\")\n",
    "print(\"FP: noncausal variable is detected as correlated with the residuals\")\n",
    "df1[[\"step\",\"associations_TP\",\"associations_FP\",\"associations_TN\",\"associations_FN\"]].groupby([\"step\"]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b70baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall TP, FP, TN, FN of the stopping criterion\n",
    "#(TP means that the selected variable was causal and the stopping criterion said to continue)\n",
    "#(FP means that the selected variable wasn't causal but the stopping criterion said to continue)\n",
    "#(TN means that the selected variable was causal but the stopping criterion said to stop)\n",
    "\n",
    "#select only timesteps before natural termination\n",
    "df1 = df[~df[\"should_have_stopped\"].isnull()]\n",
    "df1 = df1[~df1[\"should_have_stopped\"]]\n",
    "#group by chosen_in_ground_truth, create column of stopping decision\n",
    "df1[\"decide_to_stop\"] = df1[\"stopping_metric\"]>=0.05\n",
    "res=df1[[\"chosen_in_ground_truth\",\"decide_to_stop\",\"train_aic\"]].groupby([\"chosen_in_ground_truth\",\"decide_to_stop\"]).count()\n",
    "res = res.reset_index()\n",
    "dico = {(True,False):\"TP\",(True,True):\"FN\",(False,False):\"FP\",(False,True):\"TN\"}\n",
    "res[\"category\"] = res.apply(lambda r: dico[(r[\"chosen_in_ground_truth\"],r[\"decide_to_stop\"])],axis=1)\n",
    "\n",
    "print(\"Decisions by the stopping criterion.\")\n",
    "print(\"TP: the selected variable is causal, and the stopping criterion says that its inclusion is significant.\")\n",
    "print(\"FP: the selected variable isn't causal and the stopping criterion says that its inclusion is significant.\")\n",
    "res[[\"category\",\"train_aic\"]].rename(columns={\"train_aic\":\"count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994b080",
   "metadata": {},
   "source": [
    "## Causal graph construction along algorithm\n",
    "\n",
    "Individual exemple only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f648ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some dataset and file arbitrarily\n",
    "dataset_name = \"VARSmall/returns\"\n",
    "filename = df[\"filename\"].unique()[0]\n",
    "\n",
    "df1 = df[df[\"filename\"]==filename]\n",
    "#select before natural termination\n",
    "df1 = df1[~df1[\"should_have_stopped\"].isnull()]\n",
    "df1 = df1[~df1[\"should_have_stopped\"]]\n",
    "#exclude timestep of termination since the variable is said non significant by stopping criterion\n",
    "df1 = df1[~df1[\"current_is_last_model\"]]\n",
    "#relevant columns\n",
    "df1=df1[[\"dataset\",\"filename\",\"target\",\"step\",\"association_chosen\",\"chosen_in_ground_truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, var_names, causaldict = open_dataset_and_ground_truth(dataset_name, filename, rootdir=\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49444c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stepG = []\n",
    "targetlist = df1[\"target\"].unique()\n",
    "#initial step\n",
    "G = nx.DiGraph()\n",
    "for target in targetlist:\n",
    "    G.add_edge(target,target, color=\"black\")\n",
    "stepG.append(G)\n",
    "#successive steps\n",
    "for step in sorted(df1[\"step\"].unique()):\n",
    "    df_step = df1[df1[\"step\"]==step]\n",
    "    G=G.copy()\n",
    "    nx.set_edge_attributes(G,1,'width')\n",
    "    for index,row in df_step.iterrows():\n",
    "        color = \"r\" if row[\"association_chosen\"] not in causaldict[row[\"target\"]] else \"g\"  # color by causal status\n",
    "        width = 4\n",
    "        G.add_edge(row[\"association_chosen\"],row[\"target\"],color=color, width=width)\n",
    "    stepG.append(G)\n",
    "\n",
    "referenceG = nx.DiGraph()\n",
    "for target in targetlist:\n",
    "    referenceG.add_node(target)\n",
    "    for cause in causaldict[target]:\n",
    "        referenceG.add_edge(cause,target)\n",
    "for node in set(G.nodes).difference(referenceG.nodes):\n",
    "    G.add_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5eb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=nx.circular_layout(referenceG)\n",
    "connectionstyle='arc3, rad = 0.1'\n",
    "nbgraph = len(stepG)\n",
    "\n",
    "plt.subplot(2,nbgraph//2,1)\n",
    "nx.draw(referenceG,pos=pos, connectionstyle=connectionstyle,\n",
    "        labels={node: node for node in referenceG.nodes()})\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "for i in range(len(stepG)-1):\n",
    "    plt.subplot(2,nbgraph//2,2+i)\n",
    "    colors = nx.get_edge_attributes(stepG[i+1],'color').values()\n",
    "    labels = {node: node for node in stepG[i+1].nodes()}\n",
    "    width = list(nx.get_edge_attributes(stepG[i+1],'width').values())\n",
    "    nx.draw(stepG[i+1],pos=pos,\n",
    "            edge_color = colors,\n",
    "            labels=labels,\n",
    "            width = width,\n",
    "            connectionstyle=connectionstyle)\n",
    "    plt.title(\"Iteration \"+str(i+1))\n",
    "plt.savefig(\"temp.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f403c",
   "metadata": {},
   "source": [
    "# Plot comparative statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results[\"dataset\"]==\"VARSmall\"]\n",
    "\n",
    "#select only timestep of natural termination\n",
    "df1 = df[~df[\"current_is_last_model\"].isnull()]\n",
    "df1 = df1[df1[\"current_is_last_model\"]]\n",
    "\n",
    "df1[\"assoc,stopping\"]=df1['association']+\",\"+df1[\"stopping_criterion\"]\n",
    "\n",
    "sns.boxplot(df1, x=\"assoc,stopping\" , y=\"test_R2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73068764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df1, x=\"assoc,stopping\" , y=\"final_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16242060",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df1, x=\"assoc,stopping\" , y=\"final_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df1, x=\"assoc,stopping\" , y=\"test_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e8738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
